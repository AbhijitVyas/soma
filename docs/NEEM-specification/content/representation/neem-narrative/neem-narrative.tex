
% % % % % % % % % % % % % % % % % % % % % % % %
% % % Prelude
% % % % % % % % % % % % % % % % % % % % % % % %
\newcommand{\givenODPNAME}{}
\newcommand{\givenODPINTENT}{}
\newcommand{\givenODPDEFINEDIN}{}
\newcommand{\givenODPDESCRIPTION}{}
\newcommand{\givenODPGRAPHIC}{}
\newcommand{\givenODPDOMAIN}{}
\newcommand{\givenODPQUESTION}{}
\newcommand{\ODPINTENT}[1]     {\renewcommand{\givenODPINTENT}{#1}}
\newcommand{\ODPDEFINEDIN}[1]  {\renewcommand{\givenODPDEFINEDIN}{#1}}
\newcommand{\ODPDESCRIPTION}[1]{\renewcommand{\givenODPDESCRIPTION}{#1}}
\newcommand{\ODPGRAPHIC}[1]    {\renewcommand{\givenODPGRAPHIC}{#1}}
\newcommand{\ODPDOMAIN}[1]     {\renewcommand{\givenODPDOMAIN}{#1}}
\newcommand{\ODPQUESTION}[1]   {\renewcommand{\givenODPQUESTION}{#1}}
\newcommand{\OPDinit}{
  \renewcommand{\givenODPINTENT}{REQUIRED!}
  \renewcommand{\givenODPDEFINEDIN}{REQUIRED!}
  \renewcommand{\givenODPDESCRIPTION}{REQUIRED!}
  \renewcommand{\givenODPGRAPHIC}{REQUIRED!}
  \renewcommand{\givenODPQUESTION}{}
  \renewcommand{\givenODPDOMAIN}{}
  \renewcommand{\labelitemi}{$\mathbf{\sqsubseteq}$}
}

\newenvironment{owlclass}[2][,] {
  \begin{minipage}{5.0cm}
  \begin{center}
  \texttt{\bf#2} \\[-0.2cm]
  \par\noindent\rule{\textwidth}{0.4pt}
  \vspace{-0.6cm}
  \begin{itemize}[#1]
  \raggedright} {
  % % % % % %
  \end{itemize}
  \end{center}
  \end{minipage}
}

\newenvironment{ODP}[1]{
\OPDinit
\renewcommand{\givenODPNAME}{#1}
}{
\givenODPDESCRIPTION
\begin{figure}[htb]
\begin{minipage}{0.45\textwidth}
\begin{tabular}{ p{1.8cm} p{3.2cm} }
\toprule
% {\it\bf Name}                 & \emph{\givenODPNAME} \\
{\it\bf Intent}               & \givenODPINTENT \\
{\it\bf Domains}              & \givenODPDOMAIN \\
{\it\bf Competency Questions} & \givenODPQUESTION \\
{\it\bf Defined in}           & \givenODPDEFINEDIN \\
\bottomrule
\end{tabular}
\end{minipage}
\begin{minipage}{0.55\textwidth}
\begin{center}
\givenODPGRAPHIC
\end{center}
\end{minipage}
\caption{The \emph{\givenODPNAME} ODP.}
\end{figure}
}

\tikzset{owlclass/.style={draw=blue!40,fill=blue!20,rounded corners}}

% % % % % % % % % % % % % % % % %
\section{NEEM-Narrative}
\label{ch:narrative}

% NOTE: taken from KnowRob2.0
% One of the most powerful components of the human memory system is the
% episodic memory. 
When somebody talks about the deciding goal in the
last soccer world championship many of us can ``replay'' the episode
in our ``mind's eye''. %, or if somebody talks about a cross court hit
%in tennis we can recall how such a hit feels in the arm.
The memory
mechanism that allows us to recall these very detailed pieces of
information from abstract descriptions is our episodic memory.
Episodic memory is powerful because it allows us to remember special
experiences we had. It can also serve as a ``repository'' from which
we learn general knowledge.

% NOTE: taken from KnowRob2.0
EASE integrates episodic memories
deeply into the knowledge acquisition, representation, and processing
system. Whenever a robotic agent performs, observes, prospects, and
reads about an activity, it creates an episodic memory. An episodic
memory is best understood as a video that the agent makes of the
ongoing activity 
%in its inner world knowledge base
coupled with a very
detailed story about the actions, motions, their purposes, effects,
the behavior they generate, the images that are captured, etc.

% % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % %
\subsection{Scope} % Domain of Discourse
\label{sec:narrative:scope}

% NOTE: taken from SOMA paper
The broad scope of our work is everyday object manipulation tasks in autonomous robot control, and in particular the motion and force characteristics of objects that interact with each other.
The research question driving us is whether a single general control program can be written that can generate adequate behavior in many different contexts: for different tasks, objects, and environments.

% NOTE: taken from SOMA paper
One of the challenges is that, using such a general plan, the agent needs to fill the knowledge gaps between abstract instructions included in the plan and the realization of context specific behavior. That is, for example, the many ways of how humans perform a pouring task depending on the source from which is poured, the destination, and the substance that is to be poured.
Another challenge is that object manipulation tasks may fail if the agent does not perform the motions competently and well. This is caused by the agent choosing inappropriate parametrization of its control-level functions.

% NOTE: taken from SOMA paper
The employment of a general plan thus requires an abstract task and object model, and a mechanism to apply this abstract knowledge in situational context.
To achieve this, an agent needs to be equipped with the necessary common-sense and intuitive physics knowledge, which is what SOMA attempts.

\textbf{TODO: write about competency questions}

% % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % %
\subsection{Foundational Commitments}
\label{sec:narrative:commitments}

% NOTE: taken from SOMA paper
We decided to base our model on the DOLCE+DnS Ultralite (DUL) foundational framework~\cite{DOLCE2003}.
This decision is greatly motivated by their underlying ontological commitments.
%The decision to base our model on the DOLCE+DnS Ultralite foundational framework, is greatly motivated by their underlying ontological commitments.
Firstly, DUL is not a revisionary model, but seeks to express stands that shape human cognition. Furthermore it assumes a reductionist approach -- rather than capturing, for example, the flexibility of our usage of objects via multiple inheritance in a multiplicative manner, we commit to a reduced {\it ground} classification and use a {\it descriptive} approach for handling this flexibility. For this a primary branch of the ontology represents the ground {\bf physical model}, e.g. objects and actions, while a secondary branch represents the {\bf social model}, e.g. roles and tasks. All entities in the social branch would not exist without humans, i.e. they constitute social objects that represent concepts about or descriptions of ground elements. 

% NOTE: taken from SOMA paper
Every axiomatization in the physical branch can, therefore, be regarded as expressing some physical context whereas axiomatizations in the descriptive social branch are used to express social contexts. A set of dedicated relations is provided that connect both branches. For example, as detailed in Section~\ref{subsec:roles}, the relation \emph{classifies} connects ground objects, e.g. a hammer, with the roles they can play, i.e. potential classifications. Thus, we can state that a hammer can in some context be conceptualized as a murder weapon, a paper weight or a door stopper. Nevertheless, neither its ground ontological classification as a tool will change nor will hammers be subsumed as kinds of door stoppers, paper weights or weapons via multiple inheritance. Following a quick overview of the central modules of SOMA where these commitments apply, we will provide detailed examples of where and how our commitments apply in Sections~\ref{sec:perdurants} and~\ref{sec:endurants}.

% % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % %
\subsection{Taxonomy}
\label{sec:narrative:taxonomy}

\textbf{TODO: provide a broad overview about types in SOMA, what branches the ontology has. Show a Figure, maybe use this Figure to indicate in subsections at which branch in the taxonomy we are?}

% % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % %

\subsection{Actions}

\todo{Describe ACT, PROC, STATE from the SOMA paper}

\subsubsection{Ontology Design Patterns (ODP)}

\newpage
\subsubsection{Process vs. Action ODP}
\begin{ODP}{Process vs. Action}
\ODPDESCRIPTION{An Action is an Event with at least one Agent participant, such that this Agent has a Task, often defined by a Plan or Workflow, which it executes through the Action. A Process is an Event for which no such commitments have been made. In DUL, these classes are not disjoint, allowing a particular event individual to be classified as either, depending on whether we care to record an agent and its goals or not. In EASE, we use Process as a top-level class for events with no agentive participant.}
\ODPINTENT{To represent the intentional and agentive structure-- or lack thereof-- behind Events.}
\ODPDOMAIN{
  \texttt{Event classification},
  \texttt{Event narratives}}
\ODPDEFINEDIN{DUL.owl}
\ODPQUESTION{
  \emph{Is there anyone responsible for the event?}
  \emph{What are they trying to do?}
  \emph{How did an event unfold?}}
\ODPGRAPHIC{
\begin{tikzpicture}
 \node[owlclass] (ACTION) {
 \begin{owlclass}{ACTION}
  \item \texttt{Event}
  \item $(\exists \emph{hasParticipant}.\texttt{Agent})$
 \end{owlclass}
 };
 \node[owlclass,below=0.6cm of ACTION] (PROCESS) {
 \begin{owlclass}{Process}
  \item \texttt{Event}
 \end{owlclass}
 };
\end{tikzpicture}
}
\end{ODP}

\newpage

\subsection{Participants}

\todo{Describe the OBJ Module of Soma}

\subsubsection{Ontology Design Patterns (ODP)}

\todo{Objects are participants, Introduction}

\subsection{Situations}

\todo{Describe the EXEC Module of Soma}

\subsubsection{Ontology Design Patterns (ODP)}


% In version \neemversion the \neemnar consists the belief state and action task hierarchy. 
% In the following sections we will describe how the belief state and action task hierarchy are represented.
% An concrete example for a logged \neemnar will be given in Chapter \ref{ch:example}.

% \subsection{Belief State}
% \input{content/representation/neem-narrative/beliefstate}

% \subsection{Action Hierarchy}
% \label{ch:narrative,sec:actionHierarchy}
% In this section, we will describe how an action task hierarchy is represented in the \neemnar. 
% Since we are using \cram on our robots our plans do not necessary generate a sequence of actions, instead they will generate rather an hierarchy of actions.
% During the plan execution we are logging all executed actions with its parameters and represent the hierarchy in \owl.
% The general idea of the model is that an action will be represented as an individual of the class \owlClass{knowrob:'Action'}.
% This individual can be a direct instance of the class \owlClass{knowrob:'Action'} or its subclass.
% \todo{Add all supported action sub classes}
% With the predicates \owlPredicate{subAction}, \owlPredicate{previousAction} and \owlPredicate{nextAction}, which all have as subject and object the type \owlClass{knowrob:'Action'}, we are able to represent the action hierarchy.
% In our understanding an logged action hierarchy in an \owl represents all actions which were executed during an experiment.
% Meaning, if we would extracted all actions from the \owl file and recreated the action tree, we would be able to analyze and reasoning about all executed actions during one specific experiment.

% In the next subsections we will describe the predicates and classes which we currently defined in the version \neemversion to log the actions which were executed by the robot during an experiment. 

% \subsection{Action Predicates}
% Every individual of the class \owlClass{knowrob:'Action'} class or its subclass which will be logged in the \owl file can be asserted with the following predicates (see Table \ref{table:action_task_predicates}).
% Some predicates in the table are marked as required.
% This means that if you are intending to upload your \owl file to \openease, every \owlClass{knowrob:'Action'} individual has to have the required properties asserted.
% %Otherwise the \owl file will be revoked from the server.\todo{We have to implement such checking in \openease.}
% The \openease server checks also if the objects of the predicates are associated with the correct class.

% \begin{table}[H]
% 	\begin{tabular}{| c | c | c | c |}
% 		\hline			
% 		\textbf{Subject} & \textbf{Predicate} & \textbf{Object}  & \textbf{Required} \\
% 		\hline
% 		Action & taskSuccess & xsd:boolean & Yes \\
% 		\hline
% 		Action & startTime & Timepoint & Yes \\
% 		\hline
% 		Action & endTime & Timepoint  & Yes \\
% 		\hline
% 		Action & subAction & Action & No \\
% 		\hline
% 		Action & nextAction & Action & No \\
% 		\hline
% 		Action & previousAction & Action & No \\
% 		\hline
% 	\end{tabular}
% 	\caption{Action Predicates}
% 	\label{table:action_task_predicates}
% \end{table}

% \begin{description}
% 	\item[\textbf{taskSuccess}] 
% 		This predicates points to data type \owlClass{xsd:boolean}.
% 		The value \textbf{true} represents that the action was executed successfully.
% 		If any errors occurred during the action execution, the data type will be set to \textbf{false}.
% 		\footnote{In the NEEM version \neemversion we do not log the exact error which happened during action.}
% 	\item[\textbf{startTime}]
% 		The \owlPredicate{startTime} represents when the action started.
% 		Instead of representing the startTime as a data point, we are creating an instance of the class \owlClass{Timepoint}.
% 		The implemenation is done in that way because it made writing prolog queries much more convenient. 
% 		The name of the individual is representing the exact time when the action started e.g.\ \textit{timepoint\_1523878415038090} which can be understood that the action started 1523878415038090 microseconds after 00:00:00 UTC, Thursday, 1 January 1970.
% 		We are using the Unix time to represent a time point \cite{matthew2011beginning}.
% 		However, we are considering to measure the time in microseconds.
% 		The reason for this decision is that we also want to create NEEMs in simulation.
% 		However, tasks in simulation can be executed so fast that logging in microseconds allowed to measure the performance of the task executions.
% 		Also the measurement in microseconds allowed to differentiate the running time between tasks.
% 	\item[\textbf{endTime}] 
% 		This predicate represents when the action ended.
% 		More information about how we log time points is described in the predicate description \owlPredicate{startTime}.
% 	\item[\textbf{subAction}]
% 		The predicate \owlPredicate{subAction} allows to create parent-child relation between two tasks. In the context of this predicate, the subject is the parent action and the object is the child action.
% 		It is possible that an \owlClass{Action} instance can have multiple \owlPredicate{subAction} predicates which point each to a single child action.
% 	\item[\textbf{nextAction}]
% 		To be able to create an sequential order of actions which where executed on the same hierarchy level, we defined the \owlPredicate{nextAction} predicate.
% 		The subject represents the action which was started first and points to the next sibling actions.
% 		\footnote{In the NEEM version \neemversion we are not differentiate if actions were executed in sequence or in parallel.}
% 	\item[\textbf{previousAction}]
% 		Like in \owlPredicate{previousAction} this predicate is created to create an sequential order between siblings tasks.
% 		However in this case, \owlPredicate{previousAction} connects an \owlClass{Action} instance with the sibling action which was performed previously.
% \end{description}


% \subsection{Action Parameter Predicates}
% 	\label{sec:actionParameterPredicactes}
% 	In general, actions have to have parameters which have to be asserted.
% 	Based on those assertions \cram is able to infer how to perform the task.
% 	For instance, a grasping task will be executed differently when the target object is a spoon compared to when the target object is a bottle.
% 	To understand the logged behavior of the robot better, we are logging to each action the corresponding parameters.
% 	For \cram we are using for our actions a set of predefined parameters.
% 	For example, when an action requires an object every \cram action has parameter name \textit{object} asserted.
% 	During the logging process, we are creating based on the parameter's value an instance of the class \owlClass{Object} and connect this instance with the \owlPredicate{objectActedOn}.
% 	\todo{Ref to belief state when object description is done}
% 	This implementation allows us to use the logger for new actions without the need to extend the logger.
% 	As long the \cram actions will use the predefined parameter names all parameters will be logged without the need to extend the logger.
% 	All predefined parameters are represented by a separated predicates which point to the parameter value which is an individual of the corresponding \owl class.
% 	Table \ref{table:action_parameter_predicates} shows the current parameter predicates which are supported by our NEEM representation.
% 	The design of the action parameter predicates is based on the work with our \pr.
% 	Therefore in the NEEM \neemversion it might be possible that the action parameters cannot be used by everyone in this state.
	 
% \begin{table}[H]
% \begin{tabular}{| c | c | c |}
% 	\hline			
% 	\textbf{Subject} & \textbf{Predicate} & \textbf{Object} \\
% 	\hline			
% 	Action & effort & qudt\#NewtonMeter \\
% 	\hline
%     Action & position & Float \\
%     \hline
% 	Action & arm & Pr2\#Pr2RightArm \\
% 	\hline
% 	Action & bodyPartsUsed & Pr2\#Pr2RightGripper \\
% 	\hline
% 	Action & goalLocation & Pose or Connected Space Region \\
% 	\hline
%     Action & objectActedOn & Object \\
% 	\hline
% 	Action & objectType & Object \\
% 	\hline
% \end{tabular}
% 	\caption{Action Parameter Predicates}
% 	\label{table:action_parameter_predicates}
% \end{table}

% \begin{description}
% 	\item[\textbf{effort}] 
% 		Effort is the grasping force in newton-meters.
% 		To model this we are using the \qudt ontology \footnote{http://qudt.org/}.
% 	\item[\textbf{position}]
% 		We are using this predicate to log the the goal position for the gripper of the \pr.
% 		The \pr accepts a joint angle in RAD to position its gripper.
% 		We decided to use a float data type to model the position to be able to represent more different types of position.
% 		For instance, our \boxy robot uses centimeters to position the gripper.
% 		Therefore with a float representation we are able to log from both robots the position parameter.
% 	\item[\textbf{arm}]
% 		With this predicate we want to log which arm was used to by the robot.
% 		The predicate points to an instance of the specific robot arm class.
% 		For instance, to model that the \pr used a right arm to grasp a bottle we are asserting the \owlPredicate{arm} predicate to an individual of the class \owlClass{Pr2RightArm}\footnote{http://knowrob.org/kb/PR2.owl}.
% 	\item[\textbf{bodyPartsUsed}]
% 		The \owlPredicate{bodyPartsUsed} predicate should represent which body part from the robot was used to perform the task.
% 		This predicate can be used \eg to represent that a gripper was used to perform the task.
% 		Like in \dots we also want to represent the body part as instance of the class which represents the body part.
% 	\item[\textbf{goalLocation}]
% 		This predicate can be used to represent the target or location parameter of an action.
% 		This predicate is suitable to represent \eg the target location of an \textit{Going} action.
% 		We are considering to different object types to log the goal location.
% 		Since our robots are build on \ros our robots can work with \textit{Poses} \footnote{http://docs.ros.org/api/geometry\_msgs/html/msg/Pose.html}.
% 		How we represent this \owl class is stated out in section \ref{sec:pose}.
		
% 		Since we are also using \cram, our robots can also encounter \textit{location designator} as goal locations\cite{beetz2010cram}.
% 		That means \cram can handle tasks like "Go to the kitchen counter".
% 		Since locations designators are more abstract we use the \owl class \owlClass{Connected Space Region} to log them.
% 		A more detailed description is given in section \ref{sec:connectedSpaceRegion}.
		
% 	\item[\textbf{objectActedOn}]
% 		With the predicate \owlClass{objectActedOn} we want to log which objects are given as parameter to the action.
% 		For instance, we can log which objects the robots looked for during a perception task and what objects he tried to grab.
% 	\item[\textbf{objectType}]
% 		The difference of \owlPredicate{objectType} compared to \owlPredicate{objectActedOn} is that \owlPredicate{objectType} define not a specific object but rather an object in general.
% 		For instance, if the robotic agent will get a task such as "grab the milk from the fridge".
% 		Given the task, the agent knows only that it has to grab a object of the type of milk from the fridge.
% 		So at this moment the robot does not know if the a milk box is actually in the fridge.
% 		Thereofre it has to recognize the milk first.
% 		If this was sucessfull then the robot will assoicated the following task the milk ID with the predicate \owlPredicate{objectActedOn} which the object will be the link to the speicifc object in the belieft state.
% \end{description}

% \subsection{Action Parameter Classes}
% As shown in section \ref{sec:actionParameterPredicactes} we are not only using data types to log the action parameter.
% In this section we are describing the \owl classes which we introduced to be able to log all parameters which we required to log during our experiments.

% \subsubsection{Pose}
% 	\label{sec:pose}
% 	This class is used to log coordinates given as parameter.
% 	Since our robots are using \ros we are logging poses.
% 	A pose consists from a Quaternion and a 3D vector.
% 	Since both together can only describe a Pose, both entities are required to be logged.
% 	\begin{table}[H]
% 		\begin{tabular}{| c | c | c | c |}
% 			\hline			
% 			\textbf{Subject} & \textbf{Predicate} & \textbf{Object} & \textbf{Required}\\
% 			\hline
% 			Pose & quaternion & String & Yes \\
% 			\hline
% 			Pose & translation & String & Yes \\			
% 			\hline
% 		\end{tabular}
% 		\caption{Pose Predicates}
% 		\label{table:pose_predicates}
% 	\end{table}
	
% 	\begin{description}
% 		\item[Quaternion] 
% 			%Quaternions are used to describe rotations in a three dimensionally space. \todo{Set reference to a Quaternions description}
% 			In the NEEM version \neemversion we are representing quaternions as a string.
% 			For instance, the quaternion $0.5 + 0.35i + 1j +0k$ will be represented as "0.5 0.35 1 0".
% 		\item[Translation]
% 			The \owlClass{Translation} class represents the 3D vector part of the pose.
% 			In the NEEM version \neemversion we are representing vectors as a string.
% 			For instance, the vector $\begin{bmatrix} -0.759, 1.19, 0.932 \end{bmatrix}^T$ will be represented as "-0.759 1.19 0.932".
			
			



% 	\end{description}
	
	
	
% \subsubsection{Connected Space Region}
% 	\label{sec:connectedSpaceRegion}
% 	Since we are using \cram our robots are allowed to use location designators to describe location parameters which will be resolved to pose \cite{beetz2010cram}
% 	The resolving process is divided in three stages:
% 		\begin{enumerate}
% 			\item Define a abstract location or general location. For instance, "Grab the milk from the fridge.".
% 			\item \cram will try out to resolve "fridge" to an entity of the semantic map.
% 			\item The last step is to resolve the entity from the semantic map into a pose with which the robot can actually work with.
% 		\end{enumerate}
	
% 	\begin{table}[H]
% 		\begin{tabular}{| c | c | c | c |}
% 			\hline			
% 			\textbf{Subject} & \textbf{Predicate} & \textbf{Object} & \textbf{Required}\\
% 			\hline
% 			Connected Space Region & onPhysical & iai-kitchen & No \\
% 			\hline
% 		\end{tabular}
% 		\caption{Connected Space Region Predicates}
% 		\label{table:connected_space_region_predicates}
% 	\end{table}
	
% 	\begin{description}
% 		\item[onPhysical] 
% 			To be able to represent the resolution to an entity of the semantic map we defined the \owlPredicate{onPhysical} predicate.
% 			This predicate points to an instance of semantic map.
% 			For instance, to grasp an object from the kitchen counter in our kitchen we link the \owlClass{ConnectedSpaceRegion} instance to an individual of our semantic mal in this case \textit{knowrob:iai\_kitchen\_sink\_area\_counter\_top}.
% 	\end{description}

% \subsubsection{Timepoint}
% 	In the NEEM version \neemversion the \owlClass{Timepoint} does not have any predicates.
% 	An instance of the \owlClass{Timepoint} class defines a moment in time which is represented in microseconds.
% 	The exact timestamp in microseconds is represent in the name of the instance.
% 	For example, the individual with the name "timepoint\_1523878419.243441" represents a timepoint which is 1523878419243441 microseconds after 00:00:00 UTC, Thursday, 1 January 1970.
% 	We are using the Unix time to represent a time point\cite{matthew2011beginning}.
% 	This Timepoint represenation makes the prolog quering much more easier.

% \input{content/representation/neem-narrative/design-patterns/chapter}
% \input{content/representation/neem-narrative/knowledge-bases/knowledge-bases}
